🌎 PT 



Este repositório é dedicado à implementação de algoritmos de Machine Learning do zero, utilizando Python e a biblioteca NumPy. O objetivo principal é consolidar o aprendizado dos fundamentos e técnicas essenciais da área, explorando cada algoritmo desde sua base matemática até sua implementação prática.

Cada implementação busca ser didática e de fácil compreensão, servindo como um recurso para estudantes, pesquisadores e entusiastas que desejam aprofundar seus conhecimentos em aprendizado de máquina sem depender de bibliotecas de alto nível. Aqui está a lista dos algoritmos implementados:

📌 Classificação
- SVM (Support Vector Machine): Algoritmo baseado em margens que busca um hiperplano ótimo para separar classes no espaço de características.
- Perceptron: Um dos modelos mais simples de redes neurais, utilizado para tarefas de classificação linearmente separáveis.
- Naive Bayes: Algoritmo probabilístico baseado no Teorema de Bayes, eficiente para classificações de texto e problemas com variáveis independentes.
- KNN (K-Nearest Neighbors): Algoritmo baseado em instâncias que classifica novos pontos com base na proximidade de seus vizinhos mais próximos.
- Regressão Logística: Modelo estatístico para classificação binária que usa a função sigmoide para estimar probabilidades.
  
📌 Regressão
(Em breve! 🚀)

📌 Aprendizado Não Supervisionado
(Em breve! 🚀)

🌎 EN


This repository is dedicated to the implementation of Machine Learning algorithms from scratch using Python and NumPy. The primary goal is to solidify the understanding of fundamental ML concepts and techniques, exploring each algorithm from its mathematical foundations to its practical implementation.

Each implementation is designed to be educational and easy to follow, serving as a resource for students, researchers, and enthusiasts who want to deepen their knowledge of machine learning without relying on high-level libraries.

📌 Classification
- SVM (Support Vector Machine): A margin-based algorithm that finds an optimal hyperplane to separate classes in feature space.
- Perceptron: One of the simplest neural network models, used for linearly separable classification tasks.
- Naive Bayes: A probabilistic algorithm based on Bayes’ Theorem, effective for text classification and problems with independent variables.
- KNN (K-Nearest Neighbors): An instance-based algorithm that classifies new points based on their closest neighbors.
- Logistic Regression: A statistical model for binary classification that uses the sigmoid function to estimate probabilities.

📌 Regression
(Coming soon! 🚀)

📌 Unsupervised Learning
(Coming soon! 🚀)
